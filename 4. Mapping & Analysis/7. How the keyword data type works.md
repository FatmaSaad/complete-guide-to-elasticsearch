In the previous lecture, I briefly mentioned the use case for the “keyword” data type, being filtering, sorting, and aggregations.

But why is its use limited to this?

Why can’t we use it for full-text searches as with the “text” data type?

To answer those questions, we need to dive into how “keyword” fields are analyzed and stored.

Previously you saw how the “standard” analyzer is used for “text” fields.

For “keyword” fields, however, an analyzer named “keyword” is used instead.

This analyzer is actually a so-called no-op analyzer, meaning that it doesn’t do anything.

Well, besides returning the unmodified input string as a single token.

The string is not modified in any way, because it is intended for exact matching.

We can verify this by using the Analyze API that I showed you a bit earlier.

I have prepared the query for doing so, so let’s just go ahead and run it.

As you can see, the string is left entirely untouched and is just returned as a single token.

If symbols were to be stripped out, for instance, we wouldn’t be able to perform exact searches.

Why?

Because the values within the inverted index would then differ from the string that was provided within the indexed document.

Searching for the original value would therefore yield no results.

Speaking of the inverted index, let’s have a look at what it would look like a couple of documents.

As you can see, the entire field values are stored as a single term.

This is unlike the “text” fields where the “standard” analyzer is used.

Apart from tokenization, we can also see how the “keyword” analyzer does not remove any symbols from the string, and neither does it lowercase letters.

This example is good for understanding that text is left completely untouched when using the “keyword” data type.

However, it doesn’t demonstrate a realistic use case for a “keyword” field, since no one is realistically going to search for exactly those sentences.

A much more realistic use case would be to map something like e-mail addresses or article statuses as a “keyword” field.

Let’s go with a couple of documents representing users, each containing an e-mail address.

And here is what the inverted index for the “email” field would look like.

This is a much better use case, because you will almost always want to do exact matches on these kinds of values.

Notice how one of the e-mail addresses contains uppercase letters.

Often that’s what you want with “keyword” fields, but in some scenarios it might make sense to lowercase letters.

That would make sense in this example, because e-mail addresses are not case sensitive.

Apart from building custom analyzers, it’s also possible to configure existing ones.

This means that we can configure the “keyword” analyzer to use the “lowercase” token filter, causing the inverted index to look like this instead.

I will show you how to configure analyzers later in this section, so I just wanted to mention the possibility now.

Alright, let’s quickly summarize what we covered in this lecture.

Fields that use the “keyword” data type are analyzed using the “keyword” analyzer.

All this analyzer does, is to output the input string as a single token, with everything left untouched.

This single token is then placed within the inverted index for the field.

That’s why the “keyword” data type is used for exact matching and things like sorting and aggregations.

Basically structured data, which could be e-mail addresses, order statuses, product tags, etc.

