1

00:00:02,560  -->  00:00:06,990
Now that you know what sharding is all about,
let's look at something different, although

2

00:00:06,990  -->  00:00:09,520
related - namely replication.

3

00:00:10,400  -->  00:00:16,080
When we talked about sharding, you learned
that an index consists of a single shard by default.

4

00:00:16,780  -->  00:00:22,680
But what happens if the node where a shard
is stored breaks down, i.e. has a disk failure?

5

00:00:24,120  -->  00:00:29,060
The answer is simple; the data is lost, since
we have no copy of it.

6

00:00:29,620  -->  00:00:34,260
That's obviously a major problem, as hardware
can fail at any given time.

7

00:00:35,380  -->  00:00:40,460
The more hard drives that are used to run
your cluster, the higher the chances of a failure.

8

00:00:41,620  -->  00:00:46,880
Obviously this needs to be dealt with, because
we want to be able to sleep at night, knowing

9

00:00:46,880  -->  00:00:49,600
that a hard drive failure is not a disaster.

10

00:00:50,780  -->  00:00:56,240
Therefore we need some fault tolerance and
failover mechanism, which is where replication

11

00:00:56,240  -->  00:00:57,640
comes into the picture.

12

00:00:59,160  -->  00:01:04,840
Elasticsearch natively supports replication
of shards, and this is actually enabled by

13

00:01:04,840  -->  00:01:07,260
default, with zero configuration.

14

00:01:07,640  -->  00:01:08,780
How cool is that?

15

00:01:09,480  -->  00:01:16,439
Many databases also have replication functionality,
but setting it up can be quite complicated,

16

00:01:16,440  -->  00:01:19,580
so getting all of this for free is really
awesome!

17

00:01:21,400  -->  00:01:24,640
So how does replication work in Elasticsearch?

18

00:01:25,440  -->  00:01:31,359
As you know, an index is configured to store
its data within a number of shards, which

19

00:01:31,360  -->  00:01:33,900
may be stored across multiple nodes.

20

00:01:35,000  -->  00:01:39,400
Likewise, replication is also configured at
the index level.

21

00:01:39,980  -->  00:01:45,300
Replication works by creating copies of each
of the shards that an index contains.

22

00:01:46,140  -->  00:01:50,620
These copies are referred to as replicas or
replica shards.

23

00:01:51,960  -->  00:01:57,340
A shard that has been replicated one or more
times, is referred to as a primary shard.

24

00:01:58,140  -->  00:02:03,500
A primary shard and its replica shards, are
referred to as a replication group.

25

00:02:05,140  -->  00:02:10,939
Replica shards are a complete copy of a shard
that can serve search requests just like the

26

00:02:10,940  -->  00:02:12,080
primary shard.

27

00:02:13,480  -->  00:02:18,920
When creating an index, we can choose how
many replicas of each shard that we want,

28

00:02:18,920  -->  00:02:20,760
with one being the default value.

29

00:02:21,540  -->  00:02:26,800
So an index contains shards, which in turn
may contain replica shards.

30

00:02:27,220  -->  00:02:31,740
In the example diagram that you can see on
your screen, an index has been split into

31

00:02:31,740  -->  00:02:35,560
two primary shards, each having two replica
shards.

32

00:02:36,380  -->  00:02:39,920
The index therefore contains two replication
groups.

33

00:02:41,540  -->  00:02:47,580
Great, so we have physical copies of each
of our shards, but how does that help if the

34

00:02:47,580  -->  00:02:51,540
entire disk stops working, and we lose all
of its data?

35

00:02:52,360  -->  00:02:57,440
To prevent this from happening, replica shards
are never stored on the same node as their

36

00:02:57,440  -->  00:02:58,580
primary shard.

37

00:02:59,520  -->  00:03:05,400
This means that if one node disappears, there
will always be at least one copy of a shard's

38

00:03:05,400  -->  00:03:07,300
data available on a different node.

39

00:03:08,770  -->  00:03:14,420
How many copies will be left, depends on how
many replicas are configured for the index,

40

00:03:14,420  -->  00:03:16,820
and how many nodes the cluster contains.

41

00:03:17,580  -->  00:03:22,079
On the diagram, you can see that the replica
shards are placed on a different node than

42

00:03:22,080  -->  00:03:23,880
the primary shard they belong to.

43

00:03:25,820  -->  00:03:31,420
Replication only makes sense for clusters
that contain more than one node, because otherwise

44

00:03:31,420  -->  00:03:35,980
replication is not going to help if the only
available node breaks down.

45

00:03:36,680  -->  00:03:42,840
For this reason, Elasticsearch will only add
replica shards for clusters with multiple nodes.

46

00:03:43,720  -->  00:03:48,900
You can still configure an index to contain
one or more replicas for each shard, but it

47

00:03:48,900  -->  00:03:52,200
will not have any effect until an additional
node is added.

48

00:03:53,780  -->  00:03:58,500
Let's go through an example of how replication
works within an Elasticsearch cluster.

49

00:03:59,140  -->  00:04:03,980
To keep things simple, let's say that we
only have two indices within the cluster,

50

00:04:04,000  -->  00:04:06,900
and that both indices use the default configuration.

51

00:04:08,980  -->  00:04:12,320
We start out with a cluster consisting of
a single node.

52

00:04:12,320  -->  00:04:18,320
Each index contains only one shard, so the
node will contain a total of two shards.

53

00:04:19,980  -->  00:04:25,060
Even though the indices are configured to
replicate each shard once, the replica shards

54

00:04:25,060  -->  00:04:28,540
will be unassigned because we only have a
single node running.

55

00:04:30,040  -->  00:04:35,260
This is fine for a development environment
because it's only inconvenient if we lose data.

56

00:04:36,740  -->  00:04:42,360
However, for a production environment, we
really don't want to risk losing any data,

57

00:04:42,360  -->  00:04:45,500
so we decide to add an additional node to
the cluster.

58

00:04:46,900  -->  00:04:51,700
Remember that these nodes don't need to
be powerful at all; they just need to run

59

00:04:51,700  -->  00:04:55,600
on independent hardware so that there is no
single point of failure.

60

00:04:57,520  -->  00:05:03,280
Once Elasticsearch recognizes that we have
added an additional node, it will enable replication,

61

00:05:04,000  -->  00:05:06,520
meaning that the replica shards will be assigned.

62

00:05:07,280  -->  00:05:12,700
Had we configured the indices to replicate
shards twice, two replica shards would be

63

00:05:12,700  -->  00:05:16,720
placed on the other node instead, but the
concept remains the same.

64

00:05:18,920  -->  00:05:23,580
If we would then add an additional node to
the cluster, we would see that the replica

65

00:05:23,580  -->  00:05:27,140
shards would be spread out to increase the
availability even more.

66

00:05:27,760  -->  00:05:33,460
In that case, we wouldn't lose any data
even if two nodes went down at the same time.

67

00:05:35,360  -->  00:05:40,580
Typically you would be fine with one or two
replicas, but that depends on how critical

68

00:05:40,580  -->  00:05:41,760
your setup is.

69

00:05:42,490  -->  00:05:47,200
If two nodes break down at the same time,
can you then restore the data that was stored

70

00:05:47,200  -->  00:05:51,000
on them from another data source, such as
a relational database?

71

00:05:52,180  -->  00:05:56,940
And is it even acceptable for the data to
be unavailable while you restore it?

72

00:05:57,860  -->  00:06:01,920
If you are using Elasticsearch for powering
the search functionality on your personal

73

00:06:01,920  -->  00:06:06,840
WordPress blog, you would probably be fine
with this very small risk.

74

00:06:08,000  -->  00:06:13,419
On the other hand, if you are using Elasticsearch
for something critical within a hospital,

75

00:06:13,420  -->  00:06:16,120
you probably cannot afford to take that risk.

76

00:06:16,900  -->  00:06:22,960
As a rule of thumb, you should replicate shards
once, and for critical systems, you should

77

00:06:22,960  -->  00:06:24,780
replicate them twice or more.

78

00:06:25,540  -->  00:06:30,539
This also means that for a production setup,
you will need at least two nodes to protect

79

00:06:30,540  -->  00:06:32,340
yourself against data loss.

80

00:06:34,340  -->  00:06:39,820
While we are talking about preventing data
loss, I want to briefly mention that Elasticsearch

81

00:06:39,820  -->  00:06:44,040
also supports taking snapshots, just like
many databases do.

82

00:06:44,900  -->  00:06:50,120
Snapshots provide a way to take backups so
that you can restore data to a point in time.

83

00:06:51,160  -->  00:06:55,040
You can either snapshot specific indices,
or the entire cluster.

84

00:06:57,180  -->  00:07:01,420
So if we can take snapshots, why do we need
replication?

85

00:07:02,240  -->  00:07:07,740
Replication is indeed a way of preventing
data loss, but replication only works with

86

00:07:07,740  -->  00:07:13,470
"live data." This essentially means that
replication ensures that you won't lose

87

00:07:13,470  -->  00:07:17,340
the data that a given index stores at the
current point in time.

88

00:07:18,640  -->  00:07:24,100
Snapshots, on the other hand, enable you to
export the current state of the cluster (or

89

00:07:24,100  -->  00:07:25,580
specific indices) to a file.

90

00:07:26,560  -->  00:07:32,240
This file can then be used to restore the
state of the cluster or indices to that state.

91

00:07:33,360  -->  00:07:38,260
For instance, imagine that we have been tasked
to restructure how millions of documents are

92

00:07:38,260  -->  00:07:39,980
stored within an index.

93

00:07:40,980  -->  00:07:45,760
Of course we think that it's going to work,
and we have tested it on our development machine.

94

00:07:46,420  -->  00:07:53,120
To be sure that we can recover from any implications,
we snapshot the index before running the queries.

95

00:07:54,220  -->  00:07:59,699
When running the queries, things didn't
go as planned, perhaps because our test documents

96

00:07:59,700  -->  00:08:02,540
differed from the documents stored within
the live index.

97

00:08:03,340  -->  00:08:08,460
Whatever the cause, the documents got messed
up, and we need to revert the changes to get

98

00:08:08,460  -->  00:08:10,340
things back to a working state.

99

00:08:11,380  -->  00:08:16,080
Replication cannot help with that, because
replication just ensures that we don't lose

100

00:08:16,080  -->  00:08:20,480
our latest data, which has already been modified
in this example.

101

00:08:21,580  -->  00:08:26,040
Instead, we need to revert the state of the
index to the snapshot that we took.

102

00:08:26,820  -->  00:08:32,420
Doing that, we should be all good and ready
to try again after having fixed whatever went wrong.

103

00:08:34,320  -->  00:08:39,000
So hopefully you understand the difference
between snapshots and replication.

104

00:08:39,720  -->  00:08:45,520
Snapshots are commonly used for daily backups
and manual snapshots may be taken before applying

105

00:08:45,529  -->  00:08:50,160
changes to data, just to make sure that there
is a way to roll back the changes in case

106

00:08:50,160  -->  00:08:51,180
something goes wrong.

107

00:08:53,100  -->  00:08:58,400
Replication just ensures that indices can
recover from a node failure and keep serving

108

00:08:58,400  -->  00:09:00,380
requests, as if nothing had happened.

109

00:09:02,280  -->  00:09:05,880
Replication actually serves a secondary purpose
as well.

110

00:09:06,800  -->  00:09:11,500
Apart from preventing data loss, it can be
used to increase the throughput of a given

111

00:09:11,500  -->  00:09:12,460
index.

112

00:09:13,240  -->  00:09:17,560
Suppose that we have a web shop where we have
the products stored within an index named

113

00:09:17,570  -->  00:09:23,850
"products." We display the most popular
products on the front page, and we also run

114

00:09:23,850  -->  00:09:27,120
queries against the index when users search
for products.

115

00:09:28,420  -->  00:09:31,640
Needless to say, this index gets queried a
lot.

116

00:09:32,400  -->  00:09:37,740
The index is configured to only have one shard,
because we don't have that many documents;

117

00:09:38,160  -->  00:09:40,660
we just run a lot of queries against the index.

118

00:09:42,400  -->  00:09:45,340
The replica count is also set to just one.

119

00:09:45,780  -->  00:09:49,960
We are starting to experience a performance
bottleneck for the queries run against the

120

00:09:49,960  -->  00:09:54,260
index at peak hours, so we need to find a
way to handle that.

121

00:09:55,790  -->  00:10:01,120
The initial thought could be to add an additional
node to the cluster, which by the way currently

122

00:10:01,120  -->  00:10:02,940
consists of two nodes.

123

00:10:03,640  -->  00:10:08,880
Having only a primary shard and one replica
shard, that is not going to help, because

124

00:10:08,880  -->  00:10:12,360
we cannot spread these out across more than
two nodes anyway.

125

00:10:13,680  -->  00:10:18,840
For us to utilize the additional node, we
would have to increase the number of shards,

126

00:10:18,840  -->  00:10:20,940
or the number of replica shards.

127

00:10:22,580  -->  00:10:27,440
We don't really need another node, and we
also don't want to increase our costs.

128

00:10:28,920  -->  00:10:34,740
Instead, we can increase the number of replica
shards by one, or however many we need.

129

00:10:36,080  -->  00:10:41,460
Since we only have two nodes, we are not really
increasing the availability of the index,

130

00:10:41,760  -->  00:10:45,340
but we are increasing the throughput of the
index.

131

00:10:45,340  -->  00:10:46,160
But how?

132

00:10:47,060  -->  00:10:52,440
Remember how I told you that a replica shard
is a fully functional index on its own, just

133

00:10:52,440  -->  00:10:53,780
like a shard is?

134

00:10:54,640  -->  00:10:59,740
This actually means that both of the replica
shards can be queried at the same time.

135

00:11:01,180  -->  00:11:06,780
This is possible because of two things; the
fact that Elasticsearch automatically coordinates

136

00:11:06,780  -->  00:11:10,640
where queries will be executed, and parallelization.

137

00:11:12,080  -->  00:11:16,940
Elasticsearch will automatically select the
shard that will execute a given query, based

138

00:11:16,940  -->  00:11:20,260
on a number of factors that we will get back
to later in the course.

139

00:11:21,700  -->  00:11:27,320
This means that if we have three search requests
coming in at the same time, they can be executed

140

00:11:27,320  -->  00:11:32,640
on three different shards; the primary shard,
and both of the replica shards.

141

00:11:33,780  -->  00:11:39,880
So in that case we can have three queries
running at the same time, searching the same index.

142

00:11:41,000  -->  00:11:45,160
But how is that possible when we only have
two nodes, you might wonder?

143

00:11:46,080  -->  00:11:51,320
That's possible because any CPU that is
less than a decade old, has multiple cores

144

00:11:51,320  -->  00:11:53,580
- typically at least four.

145

00:11:55,220  -->  00:12:01,300
This enables the CPU to run tasks simultaneously
on each of the cores by using threads.

146

00:12:02,540  -->  00:12:07,840
In this example, this means that the node
hosting the two replica shards can run a search

147

00:12:07,840  -->  00:12:13,180
query on each of the shards in parallel, thus
increasing the throughput of the index.

148

00:12:14,160  -->  00:12:19,100
Of course adding more replica shards will
only be beneficial in terms of performance

149

00:12:19,100  -->  00:12:23,380
if the hardware resources of the node have
not yet been fully utilized.

150

00:12:24,520  -->  00:12:30,360
That's the case in our example, since the
load is unevenly distributed across our indices.

151

00:12:30,900  -->  00:12:36,260
If the nodes were already busy handling requests
for other indices, we would see little to

152

00:12:36,280  -->  00:12:39,240
no effect of adding an additional replica
shard.

153

00:12:40,240  -->  00:12:45,560
On top of that, we also need additional disk
space to store the replica shard, since it

154

00:12:45,560  -->  00:12:47,840
is a full copy of the primary shard.

155

00:12:49,580  -->  00:12:54,600
As I'm sure you can see by now, there are
a lot of variables that affect how many nodes,

156

00:12:54,600  -->  00:12:57,280
shards, and replica shards are optimal.

157

00:12:57,880  -->  00:13:02,260
This was just an example of how replication
can be used to increase the throughput of

158

00:13:02,260  -->  00:13:03,000
an index.

159

00:13:03,880  -->  00:13:10,660
So to summarize, replication serves two purposes;
increasing availability and throughput of

160

00:13:10,660  -->  00:13:11,660
an index.

161

00:13:13,060  -->  00:13:16,800
Let's head over to Kibana for a moment,
because I want to show you something.

162

00:13:18,060  -->  00:13:20,940
First up, let's actually create a new index.

163

00:13:20,949  -->  00:13:26,880
That's super easy; we just specify the "PUT"
HTTP verb, followed by the name of the index

164

00:13:26,880  -->  00:13:27,990
we want to create.

165

00:13:27,990  -->  00:13:30,260
I'll just give it a name of "pages."

166

00:13:35,960  -->  00:13:38,420
Great, our index has now been created.

167

00:13:38,940  -->  00:13:44,300
Since we didn't specify any settings, it
was created using the default settings, being

168

00:13:44,300  -->  00:13:46,420
one shard and one replica shard.

169

00:13:47,440  -->  00:13:49,220
Let's inspect the cluster again.

170

00:13:49,660  -->  00:13:54,020
For that, I have prepared two queries that
you have seen before, so let's begin by

171

00:13:54,020  -->  00:13:55,560
checking the cluster's health.

172

00:13:59,400  -->  00:14:03,800
Notice how the cluster's health has changed
from "green" to "yellow," so what's

173

00:14:03,800  -->  00:14:04,960
up with that?

174

00:14:05,780  -->  00:14:09,400
Let's list the indices that our cluster
contains for clues.

175

00:14:13,200  -->  00:14:18,959
Here we can see that the status of our newly
created index is set to "yellow." The

176

00:14:18,959  -->  00:14:24,660
reason for that, is that the index contains
a replica shard, but that shard is not allocated

177

00:14:24,660  -->  00:14:25,740
to any node.

178

00:14:26,440  -->  00:14:31,200
You already know the cause of that, being
that a replica shard is never allocated to

179

00:14:31,200  -->  00:14:33,400
the same node as its primary shard.

180

00:14:34,089  -->  00:14:39,600
And since our cluster only contains a single
node, Elasticsearch has nowhere to allocate

181

00:14:39,600  -->  00:14:40,860
the replica shard to.

182

00:14:41,920  -->  00:14:46,400
The replica shard is therefore pending to
be allocated, which will happen if we add

183

00:14:46,400  -->  00:14:47,680
an additional node.

184

00:14:48,380  -->  00:14:52,480
So that's the reason our cluster and index
is in a "yellow" state.

185

00:14:52,800  -->  00:14:57,760
The index is fully functional, but we are
at risk of a data loss in case the node goes

186

00:14:57,780  -->  00:15:01,000
down, so the "yellow" status is a warning
for that.

187

00:15:02,480  -->  00:15:06,920
Let's now list all of the shards within
our cluster, and see where they have been

188

00:15:06,920  -->  00:15:07,920
allocated.

189

00:15:07,920  -->  00:15:12,000
For that, we can use the "_cat" API and
its "shards" command.

190

00:15:23,140  -->  00:15:28,230
The results show a list of each shard along
with various information about it, including

191

00:15:28,230  -->  00:15:29,880
which index it belongs to.

192

00:15:30,880  -->  00:15:36,880
At the top, we can see two shards for our
newly created index, with one being the primary

193

00:15:36,880  -->  00:15:39,080
shard, and one being the replica shard.

194

00:15:40,020  -->  00:15:45,140
This is specified within the "prirep"
column, where "p" corresponds to "primary

195

00:15:45,149  -->  00:15:51,340
shard," and "r" corresponds to "replica
shard." The next column specifies the state

196

00:15:51,340  -->  00:15:52,730
of the shard.

197

00:15:52,730  -->  00:15:57,660
As we can see, the primary shard has a state
of "STARTED," meaning that it is fully

198

00:15:57,660  -->  00:15:59,920
functional and available for requests.

199

00:16:01,000  -->  00:16:05,870
The replica shard, on the other hand, has
a state of "UNASSIGNED," which is because

200

00:16:05,870  -->  00:16:10,220
we need to add another node to the cluster
for replication to have any effect.

201

00:16:11,900  -->  00:16:16,170
Now that you know the reason our cluster is
in a "yellow" state, let's review the

202

00:16:16,170  -->  00:16:20,040
list of indices once again, because I want
to show you one last thing.

203

00:16:24,220  -->  00:16:29,400
Did you notice that the Kibana indices are
configured with one shard and zero replicas?

204

00:16:30,560  -->  00:16:36,060
The one shard makes sense because these indices
will be storing very small amounts of data,

205

00:16:36,060  -->  00:16:38,400
and the query throughput will be limited.

206

00:16:39,280  -->  00:16:44,340
But doesn't having no replica shards put
us at risk of losing data?

207

00:16:44,700  -->  00:16:46,759
Yes, indeed it does.

208

00:16:47,380  -->  00:16:51,639
Don't be fooled by these zeroes, though,
because if we were to add another node to

209

00:16:51,640  -->  00:16:55,040
the cluster, these zeroes would increase to
one.

210

00:16:55,840  -->  00:16:56,360
How?

211

00:16:57,060  -->  00:17:02,660
Because the Kibana indices are configured
with a setting named "auto_expand_replicas"

212

00:17:02,670  -->  00:17:09,070
with a value of "0-1." What this setting
does, is to dynamically change the number

213

00:17:09,070  -->  00:17:13,340
of replicas depending on how many nodes our
cluster contains.

214

00:17:14,660  -->  00:17:19,970
When we only have a single node, there will
be zero replicas, and for more than one node,

215

00:17:19,970  -->  00:17:21,680
there will be one replica.

216

00:17:22,180  -->  00:17:27,240
You will see this in action soon, so I just
wanted to point it out now in case you were wondering.

217

00:17:28,680  -->  00:17:30,340
That's the end of this lecture.

218

00:17:30,680  -->  00:17:35,190
You should now have a decent understanding
of how replication works in Elasticsearch,

219

00:17:35,190  -->  00:17:37,270
and the purpose of having replica shards.
