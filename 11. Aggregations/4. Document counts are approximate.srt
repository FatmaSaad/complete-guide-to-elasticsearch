1
00:00:00,990 --> 00:00:07,170
先ほど､ ユニークな用語によって文書をバケットにグループ化する用語の分離を見ましたが､ 用語クエリについて知っておくべきことは､

2
00:00:07,170 --> 00:00:13,170
文書数は概算であり､ 正確であることが保証されないということです｡

3
00:00:13,680 --> 00:00:20,110
それがわかれば十分で､ 技術的なことはどうでもいいという方は､ この講義は飛ばしていただいて結構です｡

4
00:00:20,130 --> 00:00:23,820
そうでない場合は､ その理由をじっくりと説明したいと思います｡ 

5
00:00:24,580 --> 00:00:30,010
カウントが必ずしも正確でない理由は､ Elasticsearchクラスタの分散性､

6
00:00:30,010 --> 00:00:36,820
特に､ 少なくともデフォルトでは､ インデックスが複数のシャードに分散されるという事実があるからです｡

7
00:00:37,090 --> 00:00:46,210
用語集計の仕組みは､ 検索要求の処理を担当する調整ノードが､ 各シャードに対して上位のユニークな用語を求めるというものである｡

8
00:00:46,510 --> 00:00:54,640
つまり､ sizeパラメータに3つを指定すると､ 各インデックスシャードは､ そのユニークな用語のうち上位3つを提供するよう求められる｡

9
00:00:55,060 --> 00:01:01,270
それは､ インデックスのデータは複数のシャードに分割されているため､ コーディネーションノードから結果を取得し､

10
00:01:01,270 --> 00:01:09,340
それぞれのシャードから結果を取り出し､ それらを使って最終的な結果を計算するソースが1つもないからです｡

11
00:01:09,730 --> 00:01:14,110
この最後の工程で､ カウントが若干不正確になることがあるのです｡ 

12
00:01:14,110 --> 00:01:16,300
では､ その例を挙げて説明しましょう｡ 

13
00:01:16,750 --> 00:01:21,940
A､ B､ Cの3つのショット内に多数のオーダーが格納されているとする｡ 

14
00:01:22,270 --> 00:01:24,070
各注文には商品があります｡ 

15
00:01:24,070 --> 00:01:30,250
そこで､ 仮に製品名で集計すると､ 次の表のようにシャードのトップ5が表示されます｡

16
00:01:30,250 --> 00:01:32,710
括弧内はドキュメント数｡ 

17
00:01:33,010 --> 00:01:38,440
そして､ 各シャードは､ 文書数が最も多い3つの製品を取り上げることになります｡  e. 与えられた商品名を含む注文の数を調べ､

18
00:01:38,440 --> 00:01:42,640
これをコーディネートノードに送る｡

19
00:01:42,940 --> 00:01:48,400
次にこのノードは､ 各シャードから結果を取り出し､ 文書数を集計してまとめ､

20
00:01:48,400 --> 00:01:53,170
カスタム保存順が指定されていない場合に限り､ 用量でソートする｡

21
00:01:53,800 --> 00:01:58,390
それぞれの撮影結果を合計すると､ 次のような結果になります｡ 

22
00:01:58,510 --> 00:02:01,090
当社製品150台の受注

23
00:02:01,090 --> 00:02:09,520
A 80の注文は製品Bのもので､ 60の注文は製品ifのもので､ これはチャートからの結果をマージした結果です｡

24
00:02:09,850 --> 00:02:12,100
しかし､ ここでモラルが生まれる｡ 

25
00:02:12,130 --> 00:02:14,320
これは正しい結果ではありません｡ 

26
00:02:14,560 --> 00:02:15,460
その理由を見てみましょう｡ 

27
00:02:16,180 --> 00:02:24,850
最初の表を見ると､ 製品Aが全ショットでトップ3に入っており､ この製品の文書数が正しいことを意味していることがわかる｡

28
00:02:25,360 --> 00:02:30,160
各ショットには､ この製品で何枚のドキュメントが含まれているかが報告されています｡ 

29
00:02:30,160 --> 00:02:32,320
だから､ それは本当にまったく間違いない｡ 

30
00:02:32,830 --> 00:02:35,290
しかし､ ちょっとだけ製品Bを見てみましょう｡ 

31
00:02:35,290 --> 00:02:39,820
本製品は､ ショットA､ Bのトップ3に含まれますが､ 4ショットは含まれません｡ 

32
00:02:39,820 --> 00:02:41,170
C､ 4発｡ 

33
00:02:41,170 --> 00:02:44,230
Cを見ると､ 製品Bが4位にあることがわかる｡ 

34
00:02:44,710 --> 00:02:46,540
製品も同じ考え方です｡ 

35
00:02:46,540 --> 00:02:52,420
シャード､ B､ Cのトップ3に含まれるが､ ショットAには含まれない場合 グレート｡ 

36
00:02:52,420 --> 00:02:53,650
では､ これはどういうことなのか｡ 

37
00:02:54,040 --> 00:03:03,160
コーディネートノートが各ショットから受け取ったカウントを集計しているだけなので､ この2つの製品のドキュメントカウントが間違っているということです｡

38
00:03:03,280 --> 00:03:12,160
そのため､ 撮影した結果､ 製品Bと製品Fがそれぞれ指定した回数より20回多く表示されていることは知らない｡

39
00:03:12,760 --> 00:03:17,980
つまり､ 製品Bと製品Fの文書数は､ それぞれ20個ずつずれていることになる｡ 

40
00:03:18,460 --> 00:03:21,970
欠番を加味しても､ 同じ順位になる｡ 

41
00:03:21,970 --> 00:03:24,130
しかし､ 必ずしもそうではないかもしれません｡ 

42
00:03:24,430 --> 00:03:27,460
いずれにせよ､ 若干の誤解を招くようなカウントの仕方をしています｡ 

43
00:03:27,550 --> 00:03:31,390
少し専門的な話になりましたが､ ご理解いただけたでしょうか｡ 

44
00:03:31,930 --> 00:03:35,770
これは､ ドキュメント数がいかに誤解を招きやすいかを示す一例です｡ 

45
00:03:35,800 --> 00:03:41,950
これは特にsizeパラメータが低い数値に設定されている場合に問題となります｡ sizeパラメータが高いほど文書数の精度は上がりますが､

46
00:03:41,950 --> 00:03:50,080
その分クエリの速度も遅くなるので､ 実際には精度とパフォーマンスのトレードオフになります｡

47
00:03:50,680 --> 00:03:59,710
ただし､ デフォルトのサイズは10であるため､ 上位3つの単語を取得する場合よりも､ 今お見せしたようなことが起こる可能性は低くなることをお伝えしておきます｡

48
00:04:00,220 --> 00:04:08,260
これは､ 上位3つだけに興味がある場合､ サイズを10にした方が精度が高くなることも意味しています｡

49
00:04:08,560 --> 00:04:14,140
高い精度は必要なく､ 性能を向上させたいのであれば､ もちろんサイズを小さくすることも可能です｡

50
00:04:14,140 --> 00:04:18,070
でも､ ほとんど10本以上にしておくことをお勧めします｡ 

51
00:04:18,580 --> 00:04:23,800
さて､ これらすべてが問題となるのは､ 1つ以上のシャードで構成されるインスタンスの場合のみです｡ 

52
00:04:23,830 --> 00:04:28,870
インデックスのすべてが1つのシャードに保存されているデータであれば､ 正確な数値が得られます｡ 

53
00:04:29,140 --> 00:04:34,480
インデックス内のすべてのデータが1つのシャードに収まる場合は調整できますが､ 通常はインデックスごとに複数のシャードがあり､

54
00:04:34,480 --> 00:04:38,950
特にデフォルトではそうなっています｡

55
00:04:39,430 --> 00:04:39,910
わかりました｡ 

56
00:04:39,910 --> 00:04:41,470
そこで､ もうひとつだけ｡ 

57
00:04:41,500 --> 00:04:47,800
前回の講義で結果の一部であったキー名､ 暗算エラー､ 背景を思い出してください｡

58
00:04:48,040 --> 00:04:52,870
今説明したことで､ この鍵がどういうものかを説明することができるようになりました｡ 

59
00:04:53,380 --> 00:05:00,700
つまり､ キーには､ 最終結果に含まれなかった用語の最大文書数を表す数値が含まれているのである｡

60
00:05:01,270 --> 00:05:07,540
最初の表､ 特に3行目を考えてみてください｡ 

61
00:05:07,930 --> 00:05:13,180
Elasticsearchが行っているのは､ 各シャードから返された最後のタームからドキュメント数を取り出し､

62
00:05:13,180 --> 00:05:16,450
この例ではそれらを合計しています｡

63
00:05:16,450 --> 00:05:23,410
その合計が90となり､ 結果内にポンドキーのドントカウントエラーが返されることになる｡

64
00:05:23,860 --> 00:05:25,780
2つ目の表を見てみましょう｡ 

65
00:05:25,810 --> 00:05:35,260
つまり､ 最悪の場合､ 結果に含まれなかった用語が文書数90で､ 実際には2番目に多い文書数を持つこともあり得るのである｡

66
00:05:35,800 --> 00:05:40,960
この例では､ サイズが3つしかないことが問題を増幅させていることを忘れないでください｡ 

67
00:05:40,960 --> 00:05:43,570
しかし､ それはあくまで潜在的な問題を示すためのものです｡ 

68
00:05:43,900 --> 00:05:46,330
では､ この数字が何に役立つのか？

69
00:05:46,660 --> 00:05:53,950
まあ､ ほとんどの人は活用しないでしょうけど､ 誤差が出るわけですから､ 好きなようにやればいいんじゃないでしょうか｡

70
00:05:54,910 --> 00:05:59,440
この講義では､ 文書数がどのように不正確になるかを詳しく見ていきました｡ 

71
00:05:59,530 --> 00:06:02,020
ほとんどの場合､ これは問題ではありません｡ 

72
00:06:02,020 --> 00:06:04,860
でも､ その裏側を知ってほしかったんです｡ 

73
00:06:04,870 --> 00:06:11,440
多くの場合､ 上位3つの条件しか必要ない場合でも､ sizeパラメータは最小値である10に保つ必要があります｡

74
00:06:11,440 --> 00:06:15,310
例えば､ 数値が高いほど精度の高い結果が得られるからです｡ 

75
00:06:15,700 --> 00:06:21,400
さて､ 条件クエリについてある程度理解できたところで､ バケットアグリゲーションについて話を進めていきましょう｡ 
