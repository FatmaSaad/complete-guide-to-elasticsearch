# Batch processing

## Indexing documents
We started out indexing, updating, and deleting individual documents. 

Then we covered how to update and delete multiple documents at once, based on a condition that we defined.

In this lecture, I am going to show you how we can index, update, or delete many documents at once - potentially thousands at a time. 

We can do this by processing individual requests n batches; specifically by using the Bulk API.

This API accepts a number of lines, each separated by a newline character, being either \n or \r\n.

In a text editor, this just means that you will have to add a line break at the end of each line, i.e. hitting the Enter key.

Each of these lines should be a JSON object.

This format is based on a specification called NDJSON. 

The format is a bit special and difficult to explain, so let's just get right into it.

Let's begin by indexing a new document.

```
POST /_bulk

```

First, we define the HTTP verb and the endpoint.

Perhaps you noticed that we are not specifying any index name here. 

I will get back to that in a moment, so don't worry about that for now.

Next, we need to define the action that we want Elasticsearch to perform. 

We describe that within a JSON object.

```
POST /_bulk
{  }
```
We have four actions to choose from; "index," "create," "update," and "delete".

I will show you all of them, but let's begin with the "index" action.

The action should simply be defined as a key within this object, and the value for the key should be a JSON object.
Let's type that out.

```
POST /_bulk
{ "index": { } }
```
With this, Elasticsearch knows that we want to index a new document. 
We added an empty object as the value, which is where we can define metadata for the action. 
This will typically be the index name the document should be added to, and the ID of the document, which are specified with the "_index" and "_id" keys, respectively.

Let's set the index to "products" and give the document an ID of 200.

```
POST /_bulk
{ "index": { "_index": "products", "_id": 200 } }
```
Note that specifying the document's ID is optional; if you leave it out, Elasticsearch will automatically generate one for you, exactly as you saw earlier in this section when we indexed documents.

Alright, so what about the document itself, then?

Where do we define the fields and values that the document should contain?

We do that on a new line, which will also be a JSON object.

Within this object, we simply add key-value pairs, where the keys are the field names, and the values are the field values. 

Let's add the three fields that we have been using so far.

```
POST /_bulk
{ "index": { "_index": "products", "_id": 200 } }
{ "name": "Espresso Machine", "price": 199, "in_stock": 5 }
```

This will index a new document with an ID of 200, containing the fields that we just defined on the second line of the request body. 

As you can see, the first line defines the action and some metadata, while the second line defines the source document.

Before running the query, let's add another action to it, because the purpose of the Bulk API is really to perform multiple actions at once.
Specifically, let's make use of the "create" action.

 But wait a minute' What's the difference between the "index" and "create" actions, you are probably wondering?
 
 The difference is that the "create" action will fail if the document already exists, which is not the case for the "index" action.
 
If you use the "index" action, the document will be added if it doesn't already exist; otherwise it will be replaced.

With that out of the way, let's define the action and its metadata, which is going to look almost identical to the above.

```
POST /_bulk
{ "index": { "_index": "products", "_id": 200 } }
{ "name": "Espresso Machine", "price": 199, "in_stock": 5 }
{ "create": { "_index": "products", "_id": 201 } }
{ "name": "Milk Frother", "price": 149, "in_stock": 14 }
```
Typically you will add way more actions per bulk request, but let's go ahead and run this query.

```
{
  "took" : 15,
  "errors" : false,
  "items" : [
    {
      "index" : {
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "200",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 2,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 21,
        "_primary_term" : 3,
        "status" : 201
      }
    },
    {
      "create" : {
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "201",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 2,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 22,
        "_primary_term" : 3,
        "status" : 201
      }
    }
  ]
}

```
Within the results, we can find the result for each of the actions within the "items" key.

In this simple example, we can see that both documents were created successfully.

That was pretty easy, right?

Let's quickly retrieve the documents with a search query that I have prepared in advance.

## Retrieving all documents

```
GET /products/_search
{
  "query": {
    "match_all": {}
  }
}
```
And indeed we can find the documents that we just indexed within the results.

```
{
  "took" : 56,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 2,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "200",
        "_score" : 1.0,
        "_source" : {
          "name" : "Espresso Machine",
          "price" : 199,
          "in_stock" : 5
        }
      },
      {
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "201",
        "_score" : 1.0,
        "_source" : {
          "name" : "Milk Frother",
          "price" : 149,
          "in_stock" : 14
        }
      }
    ]
  }
}
```

 ## Updating and deleting documents

 Let's now turn our attention to updating and deleting documents. 

  We will do that within a new bulk request, just because we have already run the first one. 
  You can of course mix all four possible actions within the same bulk request.

  ```
  POST /_bulk
  { "update": { "_index": "products", "_id": 201 } }
  { "doc": { "price": 129 } }
  ```
  Let's begin by updating one of the documents from the previous bulk request. 
  
  Specifically the document with an ID of 201. 
  
  To do this, we specify the action and metadata exactly as we did before.

  The next line should be a JSON object containing information about what we want to update.

  The syntax is actually the same as the one you saw earlier for the Update API, just written on one line. 
  This means that we can actually add a script here if we want, but I will just keep things simple and partially update the document.

  To do that, I will add a "doc" object containing key-value pairs as you saw earlier in this section.


  Let's finish things off by deleting the document with ID 200. 

  Apart from the action being "delete," the syntax is exactly the same.

  ```
  POST /_bulk
  { "update": { "_index": "products", "_id": 201 } }
  { "doc": { "price": 129 } }
  { "delete": { "_index": "products", "_id": 200 } }
  ```
The "delete" action is the only action that doesn't expect a second line, so we are actually done.
That being said, I don't want to run the query just yet, because I want to modify it a bit. 

What on Earth am I talking about now?


## Specifying the index name in the request path

So far, we have been using the "_bulk" endpoint without specifying the index name, because we did this within each action.
That's useful for situations where there may be actions for different indices. 

If all actions are for the same index, however, we can specify the index name within the request path instead, so let's do that.

```
POST /products/_bulk
{ "update": { "_id": 201 } }
{ "doc": { "price": 129 } }
{ "delete": { "_id": 200 } }
```

It's probably no surprise to you that we can then get rid of the "_index" key within each action.

The actions are now all run against the "products" index, so let's give it a go.

Great, the results state that one document was updated, and one was deleted, which is what we expected.
 
Let's quickly run the search query again.

```
GET /products/_search
{
  "query": {
    "match_all": {}
  }
}
```
Indeed the document with ID 200 is now gone, and the document with ID 201 now has a price of 129.

```
{
  "took" : 204,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 1,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "201",
        "_score" : 1.0,
        "_source" : {
          "name" : "Milk Frother",
          "price" : 129,
          "in_stock" : 14
        }
      }
    ]
  }
}
```

**There are a couple of things to be aware of when using the Bulk API.**

 - The HTTP Content-Type header should be set as follows
   - Content-Type: application/x-ndjson
   - application/json is accepted, but that's not the correct way
 - The Console tool handles this for us
   - The Elasticsearch SDKs also handle this for us
   - Using HTTP clients, we need to handle this ourselves
 - You will see how to do this in the next lecture
 - Each line must end with a newline character (\n or \r\n)
   - This includes the last line
     - In a text editor, this means that the last line should be empty
   - Automatically handled with the Console tool
   - Typically a script will generate the bulk file, in which case you need to handle this
   - Don't type out \n or \r\n in a text editor
 - Routing is used to resolve a document's shard
   - The routing can be customized if necessary
 - The Bulk API supports optimistic concurrency control
   -  Include the if primary term and if seq no parameters within the action metadata

First, the "Content-Type" header of the HTTP request should be set as follows, being the content type for the NDJSON format.
```
Content-Type: application/x-ndjson
```

Elasticsearch will accept a value of "application/json" which should be used for all other APIs, but that's just to be nice to us.
 
The correct way is to set the content type to NDJSON as shown. 


We have just been using the Console tool so far, so we haven't had to worry about HTTP headers at all, as Kibana handles all of that for us. 

A much more realistic use of the Bulk API, however, is to invoke it from the command line or from some kind of script. 
When making use of the official lasticsearch SDK, this is handled automatically. 
I will show you how to set the header with cURL in the next lecture.

The next thing to be aware of, is really important. 

Each of the lines within the request body must end with a newline character, being either \n or \r\n. 
This includes the last line, which is a very common mistake I see people make. 

This is handled for us automatically when sending bulk requests through the Console tool, but a much more common thing to do, is to send the contents of a file as the request body. 

You will see exactly that in the next lecture.

When doing that, the last line of the file must be blank so that the file ends with a newline character. 

To be clear, you shouldn't write \n at the end of each line explicitly if you are editing the file in a text editor; simply hitting the Enter key after each line will do the trick.

Remember to do that for the last line as well.

If this is not done, the request will fail. 

The error description is actually very precise, but I still get asked how to solve it a lot, so please remember to do this. :-)

Anyway, I will show you how to do it in the next lecture, so just be aware of this requirement for now.



Another thing to keep in mind, is that if a single action fails, this will not affect the other actions, as they will proceed as normal. 
That's why Elasticsearch returns detailed information about every action within the "items" key, as you saw earlier.

The response does contain some aggregated keys that you can check to see if everything went well. 

If there were failures, you will need to inspect each item to figure out what went wrong.

Note that the entries within the "items" key are in the same order as the actions were specified in the request, so you can rely on this order.

This is another example of how some Elasticsearch APIs can partially fail.




So when should we use the Bulk API in the first place?

The Bulk API is useful when you have lots of write actions that you need to perform, because the API is much more efficient than sending hundreds or thousands of individual write requests.

A big part of the reason why this is the case, is due to the fact that a lot of network round trips are avoided.

Also, you are surely not going to type out bulk requests by hand as we did in this lecture, so the Bulk API is useful when you have a script that generates the request.

So essentially you will want to use the Bulk API when you need to perform many writes at the same time, perhaps for importing data as you will see in the next lecture.

**Two things left to mention before ending.**

The first thing is that routing is used for each action in the same way as you previously learned. 

It's possible to overwrite the default routing, but that's a more advanced topic.

Next, if you want to make use of optimistic concurrency control - as you learned a couple of lectures ago - you can actually include the "if_seq_no" and "if_primary_term" parameters within the action's metadata. 

The behavior is then exactly the same as I showed you earlier. That's useful if you use the Bulk API to update existing documents and don't want to overwrite any changes that might have been applied to the documents as a result of concurrent operations.

And that's the end of this lecture, I promise! :-)




