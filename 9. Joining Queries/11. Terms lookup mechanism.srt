1
00:00:02,330 --> 00:00:07,280
これで､ ネストされたクエリと､ ジョイント・フィールドをマッピングしてクエリする方法の両方を確認しました｡ 

2
00:00:07,310 --> 00:00:13,400
次は､ 実際に見たことのあるクルー､ すなわちタームズクエリを見てみましょう｡ 

3
00:00:13,670 --> 00:00:16,570
では､ それが巨大なフィールドとどう関係するのか｡ 

4
00:00:16,580 --> 00:00:25,190
用語クエリの基本的な使い方は､ クエリで指定した1つ以上の用語を含む文書を検索することである｡

5
00:00:25,460 --> 00:00:32,360
しかし､ 時には非常に多くの用語を調べたいことがあり､ それらを明示的にクエリ定義に含めることは現実的ではありません｡

6
00:00:32,930 --> 00:00:40,550
例えば､ 500の用語を含めたい場合､ クエリがかなり大きくなり､ 不格好になってしまうことは想像に難くありません｡

7
00:00:40,880 --> 00:00:51,620
このため､ 用語クエリは用語ルックアップ機構と呼ばれるものをサポートしています｡ これは､ ドキュメントから用語をフェッチするための実に派手なElasticsearchの専門用語にすぎません｡

8
00:00:52,160 --> 00:00:59,990
基本的には､ インデックスの種類と､ 用語を取得したい文書の識別子を指定することができる｡

9
00:01:00,290 --> 00:01:04,370
また､ 用語が格納されるフィールドのパスを指定する必要がある｡ 

10
00:01:04,790 --> 00:01:08,390
さっそくですが､ この後､ もう少しお話を伺いたいと思います｡ 

11
00:01:09,020 --> 00:01:14,240
そこで､ あらかじめテストデータを少し用意しておき､ クエリを実行済みです｡ 

12
00:01:14,630 --> 00:01:18,980
GitHubのリポジトリから探すことができますので､ 覚えておいてください｡ 

13
00:01:19,430 --> 00:01:23,840
つまり､ usersとstoriesの2つのインデックスを作成するクエリです｡ 

14
00:01:23,990 --> 00:01:30,260
各ユーザーはfollowingというフィールドを持ち､ そこには自分がフォローしているユーザーのIDが格納されています｡ 

15
00:01:30,770 --> 00:01:36,050
Instagram､ Snapchat､ Twitter､ Facebookで誰かをフォローするようなイメージです｡ 

16
00:01:36,500 --> 00:01:43,220
ここで､ あるユーザーのストーリーを表示したいのですが､ それは､ そのユーザーがフォローしているユーザーのストーリーとなります｡

17
00:01:43,700 --> 00:01:49,520
そのためには､ そのユーザーがフォローしているユーザーIDが公開しているストーリーを検索する必要があります｡ 

18
00:01:50,220 --> 00:01:56,630
そこで､ ストーリーのインデックスを検索するタームリスの前半をここに用意したのです｡ 

19
00:01:56,640 --> 00:02:01,020
そこで今度は､ どのユーザーIDのストーリーを探したいかを指定する必要があります｡ 

20
00:02:01,410 --> 00:02:05,550
そのためには､ いくつかのオプションを含むオブジェクトを追加する必要があります｡ 

21
00:02:05,580 --> 00:02:12,060
キーはストーリーのユーザーIDを含むフィールドの名前である必要があり､ この場合はuserである｡

22
00:02:12,990 --> 00:02:18,330
そこで､ この被写体のユーザーと､ とりあえず空のオブジェクトを追加してみましょう｡ 

23
00:02:19,020 --> 00:02:24,150
このオブジェクトの中で､ ElasticsearchがユーザIDを取得する場所を定義する必要があります｡ 

24
00:02:24,360 --> 00:02:30,600
これはドキュメントであるべきなので､ どのドキュメントにこの情報が含まれているかという詳細を指定する必要がある｡ 

25
00:02:30,960 --> 00:02:38,790
ここでは､ ユーザーのインデックスとアンダースコアの暗いタイプ内の次のフィールドであることを次のように指定されたユーザーを取得したい｡

26
00:02:38,790 --> 00:02:40,620
では､ それを定義して行きましょう｡ 

27
00:02:40,980 --> 00:02:52,050
そこでまず､ インデックスをusers､ タイプをunderscore darkと定義し､ IDが1のドキュメントを取得して､

28
00:02:52,500 --> 00:03:00,300
フィールドへのパスを以下のように定義してみます｡

29
00:03:01,300 --> 00:03:08,500
この場合､ 以下のフィールドはユーザーIDの配列を含むだけですが､ ネストしたオブジェクトとしてマッピングすることも可能でした｡

30
00:03:08,590 --> 00:03:13,510
その場合､ 例えば以下のようなドットIDでパスを定義すればよかったのです｡ 

31
00:03:13,540 --> 00:03:17,590
まさに､ 講義で見たように､ ネストしたデータ型とクエリを網羅する｡ 

32
00:03:18,390 --> 00:03:18,870
わかりました｡ 

33
00:03:18,870 --> 00:03:20,640
それでは､ クエリを実行してみましょう｡ 

34
00:03:23,220 --> 00:03:29,730
その結果､ ユーザー2人と3人のストーリーがマッチングしたことがわかります｡ 

35
00:03:30,210 --> 00:03:35,700
IDが1のユーザーは､ この2人のユーザーをフォローしているので､ これは予想されたことです｡ 

36
00:03:35,700 --> 00:03:38,190
だから､ すべてが私たちの意図したとおりに動くのです｡ 

37
00:03:38,880 --> 00:03:41,400
さて､ ここで何が起こったのでしょうか？

38
00:03:41,940 --> 00:03:46,020
調整ノードが検索要求を受信すると､ それをパスした｡ 

39
00:03:46,020 --> 00:03:53,700
そして､ 指定したオプションに基づいて､ 用語のクエリを満たすために用語を取得する必要があると判断しました｡

40
00:03:54,240 --> 00:04:00,420
その結果､ 指定したIDのドキュメントを取得するリクエストを送り､ 以下のフィールドの値を取って､

41
00:04:00,420 --> 00:04:03,780
termsクエリに供給しました｡

42
00:04:04,140 --> 00:04:10,770
つまり､ これは､ まずアプリケーション・レベルでユーザーをIDで検索し､ 次のフィールドの値を取って､

43
00:04:10,770 --> 00:04:15,000
それをターム・クエリーに使用するのと同じことなのです｡

44
00:04:15,570 --> 00:04:19,590
まあ､ コンセプト的には同じなんですが､ ちょっと違うんですよね｡ 

45
00:04:20,070 --> 00:04:24,720
もし､ これをアプリケーションレベルで行うとしたら､ Elasticsearchクラスタに1つのクエリではなく､

46
00:04:24,720 --> 00:04:26,430
2つのクエリをぶつけることになります｡

47
00:04:27,170 --> 00:04:31,210
Elasticsearchがクエリを通過するのにかかる時間は非常に限られています｡ 

48
00:04:31,220 --> 00:04:36,470
つまり､ この違いは主にネットワーク上でクエリーを送信するのにかかる時間に関係しています｡ 

49
00:04:36,980 --> 00:04:42,350
Elasticsearchクラスタは､ 地理的にアプリケーションサーバの近くで動作していることが望ましいのですが､

50
00:04:42,350 --> 00:04:44,420
若干のネットワーク遅延が発生します｡

51
00:04:44,900 --> 00:04:51,950
しかし､ より重要なのは､ ネットワーク上でどれだけのデータが転送されるかということです｡

52
00:04:52,400 --> 00:04:55,970
あるユーザーが何千人もの他のユーザーをフォローしているとします｡ 

53
00:04:56,000 --> 00:05:01,310
ネットワーク上で転送するデータはかなりの量になりますし､ 整数だけでなく､

54
00:05:01,310 --> 00:05:05,510
IDなどを使っていればなおさらでしょう｡

55
00:05:06,110 --> 00:05:11,330
いずれにせよ､ ポイントは､ Elasticsearchが内部でこれを行う方が効率的であるということです｡ 

56
00:05:11,750 --> 00:05:16,940
パフォーマンスの向上がどの程度になるかは､ データのマッピングの仕方とその量によります｡ 

57
00:05:17,750 --> 00:05:23,900
補足すると､ クエリの性能は用語の数に応じて徐々に低下していくことを知っておく必要がある｡

58
00:05:24,410 --> 00:05:29,270
これは､ Elasticsearchが各項目に対してメモリと処理能力を必要とするためです｡ 

59
00:05:29,570 --> 00:05:37,280
そのため､ たくさんの用語を扱っている場合､ クラスタの安定性に影響を与えないようにするため､ パフォーマンスに影響が出ることがあります｡

60
00:05:37,310 --> 00:05:43,850
約65,000語の制限がありますが､ これはインデックスごとに設定することができます｡ 

61
00:05:44,030 --> 00:05:49,640
ただ､ 多くの用語を扱うクルーがいることが予想される場合は､ この制限を念頭に置いてください｡

62
00:05:50,470 --> 00:05:51,070
わかりました｡ 

63
00:05:51,070 --> 00:06:02,050
この講義では､ 用語クエリを使って別の文書やインデックス内の用語を検索し､ 同じ用語クエリでその用語を使用する方法を説明しました｡

64
00:06:02,230 --> 00:06:10,150
そして講義の最後には､ この方法が2つのクエリで同じことをするのに比べてパフォーマンスを向上させるということを少しお話しました｡
