# Terms lookup mechanism

You have now seen both the nested query and how to map and query joint fields.

Next up, we'll be looking at a crew that you have actually seen before, namely the terms query.

So what does this have to do with giant fields?

You might wonder the basic usage of the terms query looks up documents that contain one or more terms that we specify in the query.

But sometimes we might want to look up so many terms that it's not feasible to include them in the query definition explicitly.

For example, if you want to include 500 terms, I'm sure you can imagine that the query will end up being pretty large and clunky.

For that reason, the terms query supports something called a terms lookup mechanism that's just really fancy Elasticsearch jargon for fetching the terms from a document.

Essentially, what this lets us do is to specify an index type and identifier of a document from which we want to retrieve the terms.

We also need to specify the path of the field in which the terms are stored.

Let's just dive straight in and I'll do some more talking afterwards.

So I have prepared a bit of test data in advance and I have already run the queries.

## Adding test data

```
PUT /users/_doc/1
{
  "name": "John Roberts",
  "following" : [2, 3]
}
```

```
PUT /users/_doc/2
{
  "name": "Elizabeth Ross",
  "following" : []
}
```

```
PUT /users/_doc/3
{
  "name": "Jeremy Brooks",
  "following" : [1, 2]
}
```

```
PUT /users/_doc/4
{
  "name": "Diana Moore",
  "following" : [3, 1]
}
```

```
PUT /stories/_doc/1
{
  "user": 3,
  "content": "Wow look, a penguin!"
}
```

```
PUT /stories/_doc/2
{
  "user": 1,
  "content": "Just another day at the office... #coffee"
}
```

```
PUT /stories/_doc/3
{
  "user": 1,
  "content": "Making search great again! #elasticsearch #elk"
}
```

```
PUT /stories/_doc/4
{
  "user": 4,
  "content": "Had a blast today! #rollercoaster #amusementpark"
}
```

```
PUT /stories/_doc/5
{
  "user": 4,
  "content": "Yay, I just got hired as an Elasticsearch consultant - so excited!"
}
```

```
PUT /stories/_doc/6
{
  "user": 2,
  "content": "Chilling at the beach @ Greece #vacation #goodtimes"
}
```
So the query is create two indices users and stories.

Each user has a field named following which contains the IDs of the users he or she is following.

You can think of this as following someone on Instagram, Snapchat, Twitter, or Facebook.

Now we want to display the stories for a given user, which will be the stories of the users he or she is following.

To do that, we need to search for stories published by the user IDs that the user is following.

So I have the first half of a term squirrel prepared down here which searches the stories index.

So now we need to specify which user IDs we want to find the stories for.

## Querying stories from a user's followers

```
GET /stories/_search
{
  "query": {
    "terms": {
      "user": {
        "index": "users",
        "id": "1",
        "path": "following"
      }
    }
  }
}
```
To do this, we need to add an object containing a number of options.

The key should be the name of the field that contains the user ID of the story, which is user in this case.

So let's add this subject's user and an empty object for now.

Within this object, we need to define where Elasticsearch should retrieve the user IDs from.

This should be a document, so we need to specify the details of which document contains this information.

Here we want to retrieve who are given users following being the following fields within the user's index and the underscore dark type.

So let's go ahead and define that.

So first up, I'll define the index as users, the type as underscore dark, and then let's retrieve the document with an ID of one and define the path to the fields as following.

In this case, the following fields just contains an array of user IDs, but it could also have been mapped as nested objects.

In that case, we could just have defined the path as following dot ID for instance.

Exactly as you saw in the lecture, covering the nested data type and query.

All right.

Let's go ahead and run the query.

Within the results, we can see that two stories were matched being the stories from users two and three.

This is what we expected since the user with an ID of one follows these two users.

So everything works as we intended.

All right, so what just happened here?

![](images/2022-09-21_15-26)

When the coordinating node received the search request, it passed it.

And based on the options that we specified, it determined that it needed to retrieve the terms to be able to fulfill the terms query.

As a result, it sent off a request to retrieve the document with the ID that we specified and took the value of the following fields and fed it to the terms query.

So essentially this is the same as first looking up the user by ID at the application level and then taking the value of the following fields and use that for terms query.

Well, it's conceptually the same, but not quite the same.

![](images/2022-09-21_15-27)

If we were to do this at the application level, we would be hitting the Elasticsearch cluster with two queries instead of one.

The time it takes Elasticsearch to pass a query is very limited.

So the difference is mainly related to the time it takes to send the queries over the network.

There is some network latency, although the Elasticsearch cluster is hopefully running close to the application server geographically.

More importantly, though, is how much data would be transferred over the network because this impacts performance as well.

Suppose that a user is following thousands of other users.

That's quite a bit of data to transfer on the network and it would be even worse if we were not just using integers, but we're using IDs or something like that.

Whatever the case, the point is that it's more efficient to let Elasticsearch do this internally.

How big the performance win is depends on how the data is mapped and how much of it there is.

On a quick note, you should know that the performance of the query degrades gradually based on how many terms there are.

This is because Elasticsearch needs memory and processing power for each term.

So if you're dealing with lots of terms, performance may be affected to avoid affecting the stability of the cluster.

There is a limit of around 65,000 terms, although this can be configured at a per index level.

Just keep this limit in mind if you anticipate that you will have crews that need to handle lots of terms.

All right.

So in this lecture, you saw how to use the terms query to look up terms within another document, potentially within another index, and then use those terms within the same terms query.

And at the end of the lecture, we talked a bit about how this approach improves the performance compared to doing the same thing with two queries.

